{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "secure-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Daniel/p39/lib/python3.9/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import models\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import numpy as np\n",
    "from dataloader import MNISTIndexed\n",
    "from losses import LossG, NaiveLoss\n",
    "import yaml\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "second-madison",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "becoming-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "DATASET_SIZE = 60000\n",
    "IMAGES_TO_USE = 1600\n",
    "CONTENT_CODE_LEN = 28\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aboriginal-frequency",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with seed: 42.\n"
     ]
    }
   ],
   "source": [
    "with open(\"./conf.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "seed = cfg['seed']\n",
    "if seed == -1:\n",
    "    seed = np.random.randint(2 ** 32 - 1, dtype=np.int64)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "print(f'running with seed: {seed}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "imposed-tower",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./datasets/MNIST/\"\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              ])\n",
    "\n",
    "# Download and load the data\n",
    "mnist_data = MNISTIndexed(data_path, download=True, train=True, transform=transform)\n",
    "used_indices = np.random.randint(0, DATASET_SIZE, IMAGES_TO_USE)\n",
    "mnist_subsample = torch.utils.data.Subset(mnist_data, used_indices)\n",
    "mnist_dataloader = torch.utils.data.DataLoader(mnist_subsample, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "broadband-replication",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NaiveLoss(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "directed-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.GeneratorBasic(CONTENT_CODE_LEN, 4, 10, (BATCH_SIZE, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "finite-state",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, tboard_name, loss_func, train_loader, epochs=50, lr=1e-3, noise_std=0.3, reg_factor=1e-6):\n",
    "    writer = SummaryWriter(log_dir='logs/' + tboard_name)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    " \n",
    "    # prepare the data\n",
    "    # TODO play with initizalization and refactor?\n",
    "    class_codes = torch.normal(0.5, noise_std, (10, 10)).to(device)\n",
    "    content_codes = torch.normal(0.5, noise_std, (DATASET_SIZE, CONTENT_CODE_LEN)).to(device)\n",
    "    \n",
    "    # set up some variables for the visualizations\n",
    "    display_contents = used_indices[:4]\n",
    "    display_classes = [0, 1, 2, 3]\n",
    "    \n",
    "    # sets up some stuff for visualization\n",
    "    sample_content_images = [train_loader.dataset.dataset[i][0] for i in display_contents]\n",
    "    labels = list(mnist_dataloader.dataset.dataset.targets)\n",
    "    sample_class_indices = [labels.index(i) for i in display_classes]\n",
    "    samples_classes_ims = [train_loader.dataset.dataset[i][0] for i in sample_class_indices]\n",
    "    tboard_classses = torch.cat([torch.zeros(1, 28, 28)] + samples_classes_ims).unsqueeze(1)\n",
    "    tboard_contents = torch.cat([train_loader.dataset.dataset[i][0] for i in display_contents]).unsqueeze(1)\n",
    "    \n",
    "    tboard_batch = torch.zeros((len(display_classes) + 1) * (len(display_contents) + 1), 1, 28, 28)\n",
    "    non_first_col = np.arange(tboard_batch.shape[0])\n",
    "    non_first_col = non_first_col[non_first_col % (len(display_contents) + 1) != 0]\n",
    "    tboard_batch[:tboard_batch.shape[0]:len(display_classes)+1, ...] = tboard_classses\n",
    "    \n",
    "    # start of train\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "\n",
    "        losses = []\n",
    "        for data_row in train_loader:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            images, labels, indices = data_row\n",
    "            images = images.to(device)\n",
    "\n",
    "            # create input for network\n",
    "            cur_content, cur_class = content_codes[indices], class_codes[labels]\n",
    "            cur_content.requires_grad_(True)\n",
    "            cur_class.requires_grad_(True)\n",
    "            noisy_code = cur_content + torch.rand(CONTENT_CODE_LEN) * noise_std\n",
    "            inputs = torch.cat((cur_class, noisy_code), 1)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = loss_func(torch.cat([outputs, outputs, outputs], dim=1), torch.cat([images, images, images], dim=1), cur_content)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        model.eval()\n",
    "        inputs = []\n",
    "        for disp_classes in display_classes:\n",
    "            for disp_contents in display_contents:\n",
    "                inputs.append(torch.cat((class_codes[disp_classes], content_codes[disp_contents])).unsqueeze(0))\n",
    "        outputs = model(torch.cat(inputs, 0))\n",
    "        tboard_batch[non_first_col, ...] = torch.cat((tboard_contents, outputs))\n",
    "        \n",
    "        img_grid = torchvision.utils.make_grid(tboard_batch,nrow=len(display_classes) + 1)\n",
    "        writer.add_image('images',img_grid, global_step=epoch)\n",
    "\n",
    "        writer.add_scalar('loss', np.mean(losses), global_step=epoch)\n",
    "        print(\"Epoch: {}, loss: {}\\n\".format(epoch, np.mean(losses)))\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "israeli-accuracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.3579003599286079\n",
      "\n",
      "Epoch: 1, loss: 0.3283970004320145\n",
      "\n",
      "Epoch: 2, loss: 0.3204135501384735\n",
      "\n",
      "Epoch: 3, loss: 0.3176807615160942\n",
      "\n",
      "Epoch: 4, loss: 0.3159749299287796\n",
      "\n",
      "Epoch: 5, loss: 0.315024753510952\n",
      "\n",
      "Epoch: 6, loss: 0.31379214614629747\n",
      "\n",
      "Epoch: 7, loss: 0.3133666947484016\n",
      "\n",
      "Epoch: 8, loss: 0.312555259168148\n",
      "\n",
      "Epoch: 9, loss: 0.3120495840907097\n",
      "\n",
      "Epoch: 10, loss: 0.31084557741880414\n",
      "\n",
      "Epoch: 11, loss: 0.3098355334997177\n",
      "\n",
      "Epoch: 12, loss: 0.30912124902009963\n",
      "\n",
      "Epoch: 13, loss: 0.30835670709609986\n",
      "\n",
      "Epoch: 14, loss: 0.30683549493551254\n",
      "\n",
      "Epoch: 15, loss: 0.3058952274918556\n",
      "\n",
      "Epoch: 16, loss: 0.30497590601444247\n",
      "\n",
      "Epoch: 17, loss: 0.3031943666934967\n",
      "\n",
      "Epoch: 18, loss: 0.3019557502865791\n",
      "\n",
      "Epoch: 19, loss: 0.30110628515481946\n",
      "\n",
      "Epoch: 20, loss: 0.2999091503024101\n",
      "\n",
      "Epoch: 21, loss: 0.2977066946029663\n",
      "\n",
      "Epoch: 22, loss: 0.2963382253050804\n",
      "\n",
      "Epoch: 23, loss: 0.294965295791626\n",
      "\n",
      "Epoch: 24, loss: 0.294027578830719\n",
      "\n",
      "Epoch: 25, loss: 0.29254837781190873\n",
      "\n",
      "Epoch: 26, loss: 0.2908946418762207\n",
      "\n",
      "Epoch: 27, loss: 0.2892859548330307\n",
      "\n",
      "Epoch: 28, loss: 0.2876256361603737\n",
      "\n",
      "Epoch: 29, loss: 0.28652809947729113\n",
      "\n",
      "Epoch: 30, loss: 0.2852851203083992\n",
      "\n",
      "Epoch: 31, loss: 0.2840337163209915\n",
      "\n",
      "Epoch: 32, loss: 0.2832993084192276\n",
      "\n",
      "Epoch: 33, loss: 0.2821461609005928\n",
      "\n",
      "Epoch: 34, loss: 0.28055233746767044\n",
      "\n",
      "Epoch: 35, loss: 0.27935033589601516\n",
      "\n",
      "Epoch: 36, loss: 0.27720763415098193\n",
      "\n",
      "Epoch: 37, loss: 0.2774532011151314\n",
      "\n",
      "Epoch: 38, loss: 0.2756338495016098\n",
      "\n",
      "Epoch: 39, loss: 0.274641864746809\n",
      "\n",
      "Epoch: 40, loss: 0.2731873449683189\n",
      "\n",
      "Epoch: 41, loss: 0.27308593824505806\n",
      "\n",
      "Epoch: 42, loss: 0.2718055881559849\n",
      "\n",
      "Epoch: 43, loss: 0.27109359100461006\n",
      "\n",
      "Epoch: 44, loss: 0.2697108700871468\n",
      "\n",
      "Epoch: 45, loss: 0.2677460388839245\n",
      "\n",
      "Epoch: 46, loss: 0.26835857197642327\n",
      "\n",
      "Epoch: 47, loss: 0.2675653918087482\n",
      "\n",
      "Epoch: 48, loss: 0.2666634103655815\n",
      "\n",
      "Epoch: 49, loss: 0.266259948015213\n",
      "\n",
      "Epoch: 50, loss: 0.26455863416194914\n",
      "\n",
      "Epoch: 51, loss: 0.2643177284300327\n",
      "\n",
      "Epoch: 52, loss: 0.26187715485692026\n",
      "\n",
      "Epoch: 53, loss: 0.26296865060925484\n",
      "\n",
      "Epoch: 54, loss: 0.2621781513094902\n",
      "\n",
      "Epoch: 55, loss: 0.26033933982253077\n",
      "\n",
      "Epoch: 56, loss: 0.2604012982547283\n",
      "\n",
      "Epoch: 57, loss: 0.2611396515369415\n",
      "\n",
      "Epoch: 58, loss: 0.2607078602910042\n",
      "\n",
      "Epoch: 59, loss: 0.2593632355332375\n",
      "\n",
      "Epoch: 60, loss: 0.2587659226357937\n",
      "\n",
      "Epoch: 61, loss: 0.2571061907708645\n",
      "\n",
      "Epoch: 62, loss: 0.2574346908926964\n",
      "\n",
      "Epoch: 63, loss: 0.25712844997644424\n",
      "\n",
      "Epoch: 64, loss: 0.256105877161026\n",
      "\n",
      "Epoch: 65, loss: 0.25571593552827837\n",
      "\n",
      "Epoch: 66, loss: 0.2551677666604519\n",
      "\n",
      "Epoch: 67, loss: 0.2538462246954441\n",
      "\n",
      "Epoch: 68, loss: 0.2547283311188221\n",
      "\n",
      "Epoch: 69, loss: 0.25360224559903144\n",
      "\n",
      "Epoch: 70, loss: 0.25487253308296204\n",
      "\n",
      "Epoch: 71, loss: 0.2531595033407211\n",
      "\n",
      "Epoch: 72, loss: 0.252892045378685\n",
      "\n",
      "Epoch: 73, loss: 0.2512291818857193\n",
      "\n",
      "Epoch: 74, loss: 0.25137164250016214\n",
      "\n",
      "Epoch: 75, loss: 0.2523520176112652\n",
      "\n",
      "Epoch: 76, loss: 0.25099633514881137\n",
      "\n",
      "Epoch: 77, loss: 0.25094275385141374\n",
      "\n",
      "Epoch: 78, loss: 0.2506317439675331\n",
      "\n",
      "Epoch: 79, loss: 0.24998230174183844\n",
      "\n",
      "Epoch: 80, loss: 0.25030444622039794\n",
      "\n",
      "Epoch: 81, loss: 0.2502797722816467\n",
      "\n",
      "Epoch: 82, loss: 0.24865008726716042\n",
      "\n",
      "Epoch: 83, loss: 0.2485571862757206\n",
      "\n",
      "Epoch: 84, loss: 0.24892750412225723\n",
      "\n",
      "Epoch: 85, loss: 0.24882470980286597\n",
      "\n",
      "Epoch: 86, loss: 0.2491928082704544\n",
      "\n",
      "Epoch: 87, loss: 0.24725521340966225\n",
      "\n",
      "Epoch: 88, loss: 0.24771603018045427\n",
      "\n",
      "Epoch: 89, loss: 0.2467486797273159\n",
      "\n",
      "Epoch: 90, loss: 0.24600273311138154\n",
      "\n",
      "Epoch: 91, loss: 0.2472142067551613\n",
      "\n",
      "Epoch: 92, loss: 0.24717462614178656\n",
      "\n",
      "Epoch: 93, loss: 0.2453904542326927\n",
      "\n",
      "Epoch: 94, loss: 0.2460433453321457\n",
      "\n",
      "Epoch: 95, loss: 0.24475275874137878\n",
      "\n",
      "Epoch: 96, loss: 0.24580355525016784\n",
      "\n",
      "Epoch: 97, loss: 0.24495321929454802\n",
      "\n",
      "Epoch: 98, loss: 0.24488489747047423\n",
      "\n",
      "Epoch: 99, loss: 0.2427075406908989\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, \"MNIST_baseline\", criterion, mnist_dataloader, epochs=100, lr=1e-3, noise_std=0.3, reg_factor=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-church",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
